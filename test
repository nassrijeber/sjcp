import org.apache.spark.sql.Column;
import org.apache.spark.sql.functions;

import static org.apache.spark.sql.functions.*;

public class PivotSanitizer {

  private static String q(String colName) {
    // Quote avec backticks pour gérer espaces / caractères spéciaux dans le NOM de colonne
    return "`" + colName.replace("`", "``") + "`";
  }

  /**
   * Transforme le CONTENU d'une colonne (valeur) en clé safe pour pivot/Parquet.
   */
  public static Column parquetSafeValue(String valueColName) {

    // 1) cast string + trim + lower
    Column s = lower(trim(col(valueColName).cast("string")));

    // 2) supprimer accents: normalize NFD + enlever les "combining marks" \p{M}
    // normalize() existe sur Spark 3.x (fonction SQL)
    s = regexp_replace(expr("normalize(" + "cast(" + q(valueColName) + " as string)" + ", 'NFD')"), "\\p{M}", "");

    // 3) remplacer séparateurs/espaces par underscore
    s = regexp_replace(s, "[\\s\\-/\\.]+", "_");

    // 4) enlever tout sauf [a-z0-9_]
    s = regexp_replace(s, "[^a-z0-9_]", "");

    // 5) compacter underscores + trim underscores
    s = regexp_replace(s, "_+", "_");
    s = regexp_replace(s, "^_+|_+$", "");

    // 6) fallback si null/vide
    s = when(s.isNull().or(s.equalTo("")), lit("col")).otherwise(s);

    // 7) si commence par chiffre => prefix c_
    s = when(s.rlike("^[0-9]"), concat(lit("c_"), s)).otherwise(s);

    return s;
  }
}