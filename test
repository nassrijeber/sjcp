import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.execution.QueryExecution;
import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan;
import org.apache.spark.sql.catalyst.plans.logical.Statistics;

public final class DatasetUtils {

    private DatasetUtils() {}

    public static boolean isEmptyFast(Dataset<Row> df) {
        try {
            QueryExecution qe = df.queryExecution();
            LogicalPlan optimized = qe.optimizedPlan();
            Statistics stats = optimized.stats();
            long size = stats.sizeInBytes().longValue();

            if (size == 0L) return true;
            if (size > 0L) return false;
        } catch (Throwable ignore) {}

        return df.limit(1).rdd().isEmpty();
    }
}